#rmse for training data
age_fit <- augment(ab_final_fit, new_data = data_train)
View(age_fit)
rmse(truth = age, estimate = .pred)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
collect_metrics(tune_abalone) %>% arrange(mean)
#visualizing
autoplot(tune_abalone)
collect_metrics(tune_abalone) %>% arrange(mean)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred) %>%
accuracy(truth = age, estimate = .pred)
#accuracy for training
augment(ab_final_fit, new_data = data_train) %>%
accuracy(truth = age, estimate = .pred)
#accuracy for training
augment(ab_final_fit, new_data = data_train) %>%
rsq(truth = age, estimate = .pred)
#rsq for testing
augment(ab_final_fit, new_data = data_test) %>%
rsq(truth = age, estimate = .pred)
#rsq for training
augment(ab_final_fit, new_data = data_train) %>%
rsq(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
#rsq for testing
augment(ab_final_fit, new_data = data_test) %>%
rsq(truth = age, estimate = .pred)
model_types = c("pruned tree","random forest","boosted tree")
tune_results = lst(tune_res, tune_param, tune_boost)
best_model = lst(best_penalty, best_params, best_boost)
final_models = lst(class_tree_final_fit, rf_tree_final_fit, boost_final_fit)
rocauc = c()
for (idx in 1:length(tune_results)){
performance_tbl <- collect_metrics(tune_results[[idx]]) %>% arrange(mean)
best_rocauc <- (filter(performance_tbl, .config == best_model[[idx]]['1', '.config'][[1]]))$mean
rocauc <- c(rocauc,best_rocauc)
}
# put the model types and their ROC AUC's into one table
combined <- as_tibble(cbind(model_types,rocauc))
combined
# using the table of rocaucs, find the model type with the best roc auc,
# and set "best_model" equal to that model's final workflow
best_model <- final_models[which.max(combined$rocauc)]
best_model
#re-fit on test data
test_mod <- augment(best_model[[1]], new_data = df_test)
test_mod
#ROC_AUC
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
#ROC curves
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
setwd("C:/Users/kashyap/Desktop/PSTAT-231/Final project/data/unprocessed")
df <- read.csv("bgg_dataset.csv", sep = ";")
View(df)
?clean_names
?clean_names()
#packages
library(janitor)
library(tidyverse)
df_clean <- as_tibble(df) %>%
clean_names()
View(df_clean)
?replace
?str_replace_all
df_clean[c("rating_average","complexity_average")] %>%
lapply(df[c("rating_averagcomplexity_average")], as.numeric(str_replace_all(x,",",".")))
df_clean[c("rating_average","complexity_average")] <- lapply(df[c("rating_averagcomplexity_average")], as.numeric(str_replace_all(x,",",".")))
##function to convert string to number
convert_string <- function(x){
as.numeric(str_replace_all(x,",","."))
}
df_clean[c("rating_average","complexity_average")] <- lapply(df[c("rating_averagcomplexity_average")], convert_string)
df_clean[c("rating_average","complexity_average")] <- lapply(df[c("rating_average","complexity_average")], convert_string)
df_clean[c("rating_average","complexity_average")] <- lapply(df_clean[c("rating_average","complexity_average")], convert_string)
head(df_clean)
#data overview
summary(df_clean)
head(df_clean)
summary(df_clean)
View(df_clean)
summary(df_clean)
#dropping the NA values in Owned users
is.na(df_clean$owned_users)
#dropping the NA values in Owned users
df_comp <- na.omit(df_clean)
#changing year published to a time scale by converting it to game age
df_comp$game_age <- 2022 - df_clean$year_published
?lapply
?sapply
#changing year published to a time scale by converting it to game age
df_comp$game_age <- sapply(df_comp["year_published"],2022 - df_clean$year_published)
2022 - y
#changing year published to a time scale by converting it to game age
convert_year <- function(y){
2022 - y
}
df_comp$game_age <- sapply(df_comp["year_published"], convert_year)
View(df_comp)
df_comp$game_age
#dropping the NA values - mostly in Owned users
df_comp <- na.omit(df_clean)
#reading in data
df <- read.csv("bgg_dataset.csv", sep = ";")
df_clean <- as_tibble(df) %>%
clean_names()
#data overview
summary(df_clean)
#changing rating scores to numbers
convert_string <- function(x){
as.numeric(str_replace_all(x,",","."))
}
df_clean[c("rating_average","complexity_average")] <- lapply(df_clean[c("rating_average","complexity_average")], convert_string)
head(df_clean)
summary(df_clean)
#dropping the NA values - mostly in Owned users
df_comp <- na.omit(df_clean)
#changing year published to a time scale by converting it to game age
convert_year <- function(y){
2022 - y
}
df_comp$game_age <- sapply(df_comp$year_published, convert_year)
df_comp$game_age
summary(df_comp)
#checking nas in domain and mechanics
is.na(df_comp$mechanics)
?count
#checking nas in domain and mechanics
count(is.na(df_comp$mechanics), TRUE)
#checking nas in domain and mechanics
df_comp %>%
is.na(mechanics) %>%
count(sort = TRUE)
#checking nas in domain and mechanics
df_comp %>%
count(sort = TRUE)
#checking nas in domain and mechanics
df_comp %>%
count(NA)
#checking nas in domain and mechanics
df_comp %>%
is.na() %>%
count()
?tally
#checking nas in domain and mechanics
df_comp %>%
is.na() %>%
tally()
?where
#checking nas in domain and mechanics
df_comp %>%
select() %>%
where() %>%
is.factor()
library(tidyselect)
#checking nas in domain and mechanics
df_comp %>%
select() %>%
where() %>%
is.factor()
#checking nas in domain and mechanics
df_comp$mechanics %>%
select() %>%
where() %>%
is.factor()
#checking nas in domain and mechanics
df_comp$mechanics %>%
select(where(is.na()))
#checking nas in domain and mechanics
where(is.na(df_comp$mechanics))
#checking nas in domain and mechanics
locate(is.na(df_comp$mechanics))
?locate
?location
#checking nas in domain and mechanics
location(is.na(df_comp$mechanics))
#checking nas in domain and mechanics
changes(is.na(df_comp$mechanics))
#checking nas in domain and mechanics
is.na(df_comp$mechanics)
#checking nas in domain and mechanics
df_comp[is.na(df_comp$mechanics),]
#checking nas in domain and mechanics
df_comp[is.null(df_comp$mechanics),]
#checking nas in domain and mechanics
df_comp[is_empty(df_comp$mechanics),]
#checking nas in domain and mechanics
df_comp[is_empty(df_comp$mechanics)]
#checking nas in domain and mechanics
nas <- df_comp[is_empty(df_comp$mechanics)]
View(nas)
as.numeric(str_replace_all(x,"\",",""))
str_replace_all(z, "/",",")
df_comp$mechanics <- lapply(df$Mechanics, clean_string)
#some special characters in mechanics -- change to commas
clean_string <- function(z){
str_replace_all(z, "/",",")
}
df_comp$mechanics <- lapply(df$Mechanics, clean_string)
df_comp$mechanics <- lapply(df_com$mechanics, clean_string)
df_comp$mechanics <- lapply(df_comp$mechanics, clean_string)
df_comp$domains
df_comp$mechanics
?clean_string
clean_names(df_comp$mechanics)
library(janitor)
library(tidyverse)
library(tidyselect)
df <- read.csv("bgg_dataset.csv", sep = ";")
print("Oldest game in the data was published in:", min(df_clean$year_published))
min(df_clean$bgg_rank)
print("Oldest game in the data was published in:", min(df_clean$year_published))
print("Oldest game in the data was published in:", min(df_clean["year_published"])
print("Oldest game in the data was published in:", min(df_clean["year_published"]))
summary(df_clean)
df_clean$game_age <- sapply(df_clean$year_published, convert_year)
summary(df_clean)
print("The oldest game in the data set is:", max(df_clean["game_age"]))
print("The oldest game in the data set is:", max(df_clean$game_age))
?max
sort(df_clean$game_age)
sort(df_clean$game_age, decreasing = FALSE)
sort?
?sort
sort(df_clea["game_age"], decreasing = FALSE)
sort(df_clean["game_age"], decreasing = FALSE)
df_clean[c("rating_average","complexity_average")] <- lapply(df_clean[c("rating_average","complexity_average")], convert_string)
head(df_clean)
summary(df_clean)
df_comp <- na.omit(df_clean)
summary(df_comp)
nas <- df_comp[is_empty(df_comp$mechanics)]
nas <- df_comp[is.na(df_comp$mechanics)]
nas <- df_comp[is.na(df_comp)]
?where
nas <- where(is.na(df_comp$mechanics))
df_comp
View(df_comp)
df_comp$domains[1]
df_comp$domains[-1]
df_comp$domains[-1:]
df_comp$domains[19000]
na
df_clean[df_clean == ""] <- NA
summary(df_comp)
#counting NAs
df_clean[df_clean == ""]
#counting NAs
df_clean[df_clean == NA]
#counting NAs
shape(df_clean[df_clean == NA])
?shape
#counting NAs
dim(df_clean[df_clean == NA])
#checking nas in domain and mechanics
df_clean[df_clean == ""] <- NA
df_clean[19000]
#checking nas in domain and mechanics
df_comp[df_comp == ""] <- NA
df_comp[19000]
df_comp[19000,]
df_comp[19000,"domains"]
#counting NAs
dim(df_comp[df_comp == NA])
#counting NAs
dim(df_comp[df_comp == 2007])
dim(df_comp[19000,"domains"])
#counting NAs
dim(df_comp[df_comp == 2007])
#counting NAs
dim(df_comp[df_comp$domains == NA])
#counting NAs
df_comp[,df_comp$domains == NA]
#counting NAs
df_comp[df_comp$domains == NA,]
#counting NAs
dim(df_comp[df_comp$domains == NA,])
dim(df_comp[df_comp$domains != NA,])
View(df_comp)
View(df_comp)
#counting NAs
dim(df_comp[is.na(df_comp$domains),])
dim(df_comp[~is.na(df_comp$domains),])
dim(df_comp[!is.notna(df_comp$domains),])
dim(df_comp[!is.na(df_comp$domains),])
#counting NAs
dim(df_comp[is.na(df_comp$domains),])
dim(df_comp[!is.na(df_comp$domains),])
dim(df_comp[is.na(df_comp$domains),])
dim(df_comp[is.na(df_comp$mechanics),])
dim(df_comp[!is.na(df_comp$mechanics),])
#packages
library(janitor)
library(tidyverse)
library(tidyselect)
#reading in data
df <- read.csv("bgg_dataset.csv", sep = ";")
df_clean <- as_tibble(df) %>%
clean_names()
#data overview
summary(df_clean)
#changing rating scores to numbers
convert_string <- function(x){
as.numeric(str_replace_all(x,",","."))
}
df_clean[c("rating_average","complexity_average")] <- lapply(df_clean[c("rating_average","complexity_average")], convert_string)
head(df_clean)
summary(df_clean)
#dropping the NA values - mostly in Owned users
df_comp <- na.omit(df_clean$owned_users)
#dropping the NA values - mostly in Owned users
df_comp <- na.omit(df_clean)
#changing year published to a time scale by converting it to game age
convert_year <- function(y){
2022 - y
}
df_comp$game_age <- sapply(df_comp$year_published, convert_year)
#summary of new df
summary(df_comp)
#changing year published to a time scale by converting it to game age
convert_year <- function(y){
2022 - y
}
df_comp$game_age <- sapply(df_comp$year_published, convert_year)
#summary of new df
summary(df_comp)
#checking nas in domain and mechanics
df_comp[df_comp == ""] <- NA
df_comp[19000,"domains"]
#counting NAs
dim(df_comp[is.na(df_comp$domains),])
dim(df_comp[!is.na(df_comp$domains),])
dim(df_comp[is.na(df_comp$mechanics),])
df_comp[19000,"mechanics"]
df_comp[20000,"mechanics"]
df_comp[18000,"mechanics"]
df_comp[17000,"mechanics"]
?lapply
#replacing NA values
df_comp[df_comp$domains == NA] <- "Basic"
View(df_comp)
#replacing NA values
df_comp[is.na(df_comp$domains)] <- "Basic"
df_comp$domains
?replace
#replacing NA values
df_comp$domains <- replace(df_comp$domains, is.na(df_comp$domains), "Basic")
df_comp$domains
df_comp$mechanics <- replace(df_comp$mechanics, is.na(df_comp$mechanics), "Not mentioned")
View(df_comp)
clean_string <- function(z){
str_replace_all(z, "/",",")
}
df_comp$mechanics <- lapply(df_comp$mechanics, clean_string)
df_comp$domains
df_comp$mechanics
df_comp$mechanics
View(df_comp)
#converting to string
df_comp$mechanics <- as.character(df_comp$mechanics)
View(df_comp)
#saving to csv
write.csv(df_comp, "C:\Users\kashyap\Desktop\PSTAT-231\Final project\data\processed\cleaned.csv", row.names=FALSE)
#saving to csv
write.csv(df_comp, "C:\\Users\\kashyap\\Desktop\\PSTAT-231\\Final project\\data\\processed\\cleaned.csv", row.names=FALSE)
#reading in data
setwd("C:\\Users\\kashyap\\Desktop\\PSTAT-231\\Final project\\data\\unprocessed")
#reading in data
setwd("C:\\Users\\kashyap\\Desktop\\PSTAT-231\\Final project\\data\\processed")
df_comp <- read.csv("cleaned.csv")
View(df_comp)
#pair plot
pairs(df_comp)
#pair plot
pairs(is.numeric(df_comp))
#pair plot
pairs(select(is.numeric(df_comp)))
#pair plot
pairs(select(where(is.numeric(df_comp))))
#packages
library(dplyr)
?where
library(tidyselect)
#pair plot
select(where(is.numeric(df_comp)))
rlang::last_error()
is.numeric(df_comp)
is.numeric()
?is.numeric
#pair plot
select(where(is.numeric(df_comp)))
#pair plot
select(is.numeric(df_comp))
#pair plot
filter(is.numeric(df_comp))
#pair plot
select_if(df_comp, is.numeric)
#pair plot
pair(select_if(df_comp, is.numeric))
#pair plot
pairs(select_if(df_comp, is.numeric))
#pair plot
df_numeric <- select_if(df_comp, is.numeric))
#pair plot
df_numeric <- select_if(df_comp, is.numeric)
pairs(df_numeric)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyselect)
library(corrplot)
library(ggplot2)
library(GGally)
library(reticulate)
library(tidymodels)
library(tidyverse)
library(janitor)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(vip)
library(caret)
library(broom)
library(boot)
library(data.table)
library(mlr)
install.packages("mlr")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyselect)
library(corrplot)
library(ggplot2)
library(GGally)
library(reticulate)
library(tidymodels)
library(tidyverse)
library(janitor)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(vip)
library(caret)
library(broom)
library(boot)
library(data.table)
library(mlr)
library(ClusterR)
install.packages("cluster")
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
install.packages("devtools")
install_github("vqv/ggbiplot")
library(devtools)
install_github("vqv/ggbiplot")
library("ggbiplot")
install.packages("ClusterR")
library(devtools)
install_github("vqv/ggbiplot")
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyselect)
library(corrplot)
library(ggplot2)
df <- read.csv("C:\\Users\\kashyap\\Desktop\\PSTAT-231\\Final project\\data\\processed\\cleaned_final.csv")
drop <- c("year_published", "id", "name", "Stars", "owned_users", "mechanics", "domains")
df = df[,!(names(df) %in% drop)]
#splitting data
set.seed(1212)
df_split <- initial_split(df, strata = "rating_average")
#model
tree_spec <- decision_tree() %>%
set_engine("rpart") %>%
set_mode("regression")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyselect)
library(corrplot)
library(ggplot2)
install.packages("vctrs")
install.packages("vctrs")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyselect)
library(corrplot)
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
?vctrs
