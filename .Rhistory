roc_auc(truth = type_1, estimate = .pred)
augment(rf_tree_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred)
augment(rf_tree_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
augment(class_tree_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
vip(rf_tree_final_fit)
rf_tree_final_fit %>%
extract_fit_parsnip() %>%
vip()
summary(df_train)
rf_tree_final_fit %>%
extract_fit_parsnip() %>%
vip()
rf_tree_final_fit %>%
extract_fit_parsnip() %>%
vip()
summary(df_train)
df_train %>%
summary() %>%
group_by(type_1)
?group_by
df_train %>%
summary() %>%
group_by()
df_train %>%
group_by(type_1)
grouping <- df_train %>%
group_by(type_1)
View(grouping)
summarise(df_train)
?summarise
summarise(df_train, .groups = type_1)
df_train %>% group_by(type_1) %>% summarise(mean = mean(sp_atk), n =n())
rf_tree_final_fit %>%
extract_fit_parsnip() %>%
vip()
df_train %>%
group_by(type_1) %>%
summarise(mean = mean(sp_atk), n =n())
boost_spec <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
#workflow
boost_wf <- workflow() %>%
add_model(boost_spec) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
boost_grid <- grid_regular(trees(range = c(10,2000)), levels = 10)
View(best_penalty)
View(boost_grid)
#model
boost_spec <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
#workflow
boost_wf <- workflow() %>%
add_model(boost_spec) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
boost_grid <- grid_regular(trees(range = c(10,2000)), levels = 10)
set.seed(1212)
tune_boost <- tune_grid(
boost_wf,
resamples = df_fold,
grid = boost_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = T)
)
install.packages("xgboost")
#model
boost_spec <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
#workflow
boost_wf <- workflow() %>%
add_model(boost_spec) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
boost_grid <- grid_regular(trees(range = c(10,2000)), levels = 10)
set.seed(1212)
tune_boost <- tune_grid(
boost_wf,
resamples = df_fold,
grid = boost_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = T)
)
#visual
autoplot(tune_boost)
#best model
best_boost <- select_best(tune_boost, metric = "roc_auc")
roc_auc(best_boost)
roc_auc(best_boost, truth = type_1, estimate = .pred_Bug:.pred_Water)
best_boost
best_boost <- select_best(tune_boost, metric = "roc_auc")
best_boost
boost_final <- finalize_workflow(boost_wf, best_boost)
boost_final_fit <- fit(boost_final, data = df_train)
boost_final_fit
augment(boost_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
augment(boost_final_fit, new_data = df_fold) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
augment(boost_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
?collect_metrics
collect_metrics(tune_boost)
collect_metrics(tune_boost) %>% arrange(.metric)
#visual
autoplot(tune_boost)
?collect_predictions
collect_metrics(tune_boost) %>% arrange(roc_auc)
roc_auc(best_boost, truth = type_1, .pred_class)
best_boost
roc_auc(best_boost, truth = type_1, .pred_Class)
roc_auc(best_boost)
collect_metrics(tune_boost) %>% arrange(mean)
tune_param %>%
collect_metrics() %>%
arrange(mean)
best_params
tune_res %>%
collect_metrics() %>%
arrange(mean)
best_boost
best_boost
models <- c("pruned tree","random forest","boosted tree")
roc_auc <- c(0.64,0.73,0.71)
combined <- models + roc_auc
combined <- c(models,roc_auc)
combined <- as.data.frame(c(models,roc_auc))
View(combined)
combined <- as.data.frame(cbind(models,roc_auc))
View(combined)
combined <- as.tibble(cbind(models,roc_auc))
combined <- as_tibble(cbind(models,roc_auc))
View(combined)
combined
combined <- cbind(best_boost,best_params,best_penalty)
View(combined)
combined <- c(best_boost,best_params,best_penalty)
View(combined)
combined <- as.tibble(c(best_boost,best_params,best_penalty))
combined <- as_tibble(c(best_boost,best_params,best_penalty))
#combined <- as_tibble(c(best_boost,best_params,best_penalty))
#RF model is already finalized
rf_tree_final_fit
augment(rf_tree_final_fit, new_data = df_test)
rocauc <- c(0.64,0.73,0.71)
augment(rf_tree_final_fit, new_data = df_test) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
augment(rf_tree_final_fit, new_data = df_test) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
roc_curve()
augment(rf_tree_final_fit, new_data = df_test) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water)
test_mod <- augment(rf_tree_final_fit, new_data = df_test)
test_mod
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water)
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
roc_curve(truth = type_1, estimate = .pred_Class)
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Class)
?roc_curve
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water)
df_test$type_1 <- as.factor(df_test$type_1)
test_mod <- augment(rf_tree_final_fit, new_data = df_test)
test_mod
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water)
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
#ROC curves
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
models <- c("pruned tree","random forest","boosted tree")
rocauc <- c(0.64,0.73,0.71)
combined <- as_tibble(cbind(models,roc_auc))
combined
select_best(combined, metric = "roc_auc")
library(caret)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(janitor)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(vip)
library(caret)
library(broom)
library(boot)
pokemon <- read.csv("Pokemon.csv")
pokemon_clean <- as_tibble(pokemon) %>%
clean_names()
#visualizing types
ggplot(pokemon_clean, aes(x = type_1)) +
geom_bar(stat = "count", fill = "steelblue") +
theme_classic() +
coord_flip() +
xlab("Primary Type") +
ylab("Count")
#filtering data
df_filtered <- filter(pokemon_clean, type_1 == "Bug" | type_1 == "Fire" | type_1 == "Grass"
| type_1 == "Normal" | type_1 == "Water" | type_1 == "Psychic")
#checking new dataframe
summary(factor(df_filtered$type_1))
#converting to factors
df_filtered$type_1 <- as.factor(df_filtered$type_1)
df_filtered$legendary <- as.factor(df_filtered$legendary)
df_filtered$generation <- as.factor(df_filtered$generation)
#splitting data
set.seed(1212)
df_split <- initial_split(df_filtered, strata = "type_1")
df_train <- training(df_split)
df_test <- testing(df_split)
#v-fold
df_fold <- vfold_cv(df_train, v = 5, strata = "type_1")
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_train)
pokemon_recipe <- simple_rec1 %>%
step_dummy(legendary) %>%
step_dummy(generation) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
pokemon_recipe
summary(df_train)
mat <- select(df_train,total:speed)
mat %>%
cor() %>%
corrplot(type = "lower", diag = F, method = 'color')
#model
tree_spec <- decision_tree() %>%
set_engine("rpart") %>%
set_mode("classification")
#workflow
tree_wf <- workflow() %>%
add_model(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
#tuning cost_complexity
set.seed(1212)
param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)
tune_res <- tune_grid(
tree_wf,
resamples = df_fold,
grid = param_grid,
metrics = metric_set(roc_auc)
)
tune_res
#visualizing
autoplot(tune_res)
tune_res %>%
collect_metrics() %>%
arrange(mean)
best_penalty <- select_best(tune_res, metric = "roc_auc")
best_penalty
#finalizing workflow and fit
class_tree_final <- finalize_workflow(tree_wf, best_penalty)
class_tree_final_fit <- fit(class_tree_final, data = df_train)
augment(class_tree_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
#visualizing the tree
class_tree_final_fit %>%
extract_fit_engine() %>%
rpart.plot()
#model
rf_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
p_grid <- grid_regular(mtry(range = c(1,8)),trees(range = c(100,500)),
min_n(range = c(1,10)), levels = 8)
#workflow
rf_tree_wf <- workflow() %>%
add_model(rf_spec) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
tune_param <- tune_grid(
rf_tree_wf,
resamples = df_fold,
grid = p_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = T)
)
View(tree_wf)
autoplot(tune_param)
abalone_df <- read.csv("abalone.csv")
tune_param %>%
collect_metrics() %>%
arrange(mean)
best_params <- select_best(tune_param, metric = "roc_auc")
best_params
#finalizing workflow and fit
rf_tree_final <- finalize_workflow(rf_tree_wf, best_params)
rf_tree_final_fit <- fit(rf_tree_final, data = df_train)
rf_tree_final_fit
augment(rf_tree_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
rf_tree_final_fit %>%
extract_fit_parsnip() %>%
vip()
df_train %>%
group_by(type_1) %>%
summarise(mean = mean(sp_atk), n =n())
#model
boost_spec <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
#workflow
boost_wf <- workflow() %>%
add_model(boost_spec) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
#parameter grid
set.seed(1212)
boost_grid <- grid_regular(trees(range = c(10,2000)), levels = 10)
#tuning
tune_boost <- tune_grid(
boost_wf,
resamples = df_fold,
grid = boost_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = T)
)
#visual
autoplot(tune_boost)
#best model
best_boost <- select_best(tune_boost, metric = "roc_auc")
best_boost
boost_final <- finalize_workflow(boost_wf, best_boost)
boost_final_fit <- fit(boost_final, data = df_train)
boost_final_fit
augment(boost_final_fit, new_data = df_train) %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
collect_metrics(tune_boost) %>% arrange(mean)
models <- c("pruned tree","random forest","boosted tree")
rocauc <- c(0.64,0.73,0.71)
combined <- as_tibble(cbind(models,roc_auc))
combined
#select_best(combined, metric = "roc_auc")
#combined <- as_tibble(c(best_boost,best_params,best_penalty))
#RF model is already finalized
rf_tree_final_fit
#final fit on test data
test_mod <- augment(rf_tree_final_fit, new_data = df_test)
test_mod
#ROC_AUC
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
#ROC curves
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
#setup
data_input <- read.csv("abalone.csv")
data <- as_tibble(data_input) %>%
mutate(age = rings+1.5)  %>%
mutate(type = factor(type))  %>%
select(-rings)
#splitting data
set.seed(3435)
data_split <- initial_split(data, strata = "age")
data_train <- training(data_split)
data_test <- testing(data_split)
#model
abalone_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
#tuning grid
ab_grid <- grid_regular(mtry(range = c(1,8)),trees(range = c(100,500)),
min_n(range = c(1,10)), levels = 8)
#workflow
abalone_wf <- workflow() %>%
add_model(rf_spec) %>%
add_formula(age ~ longest_shell + diameter + height + whole_weight + shucked_weight +
viscera_weight + shell_weight + type)
#v-fold for cross-alidation
data_fold <- vfold_cv(data_train, v=5, strata = "age")
#tuning
tune_abalone <- tune_grid(
abalone_wf,
resamples = data_fold,
grid = ab_grid,
metrics = metric_set(rsq),
control = control_grid(verbose = T)
)
#workflow
abalone_wf <- workflow() %>%
add_model(abalone_spec) %>%
add_formula(age ~ longest_shell + diameter + height + whole_weight + shucked_weight +
viscera_weight + shell_weight + type)
#v-fold for cross-alidation
data_fold <- vfold_cv(data_train, v=5, strata = "age")
#tuning
tune_abalone <- tune_grid(
abalone_wf,
resamples = data_fold,
grid = ab_grid,
metrics = metric_set(rsq),
control = control_grid(verbose = T)
)
#visualizing
autoplot(tune_abalone)
#best model
ab_best <- select_best(tune_abalone, metric = "rsq")
#finalizing workflow
ab_final <- finalize_workflow(abalone_wf, ab_best)
ab_final_fit <- fit(ab_final, data = data_train)
ab_final_fit <- fit(ab_final, data = data_train)
ab_final_fit
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred_Age)
#rmse for training data
age_fit <- augment(ab_final_fit, new_data = data_train)
View(age_fit)
rmse(truth = age, estimate = .pred)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
collect_metrics(tune_abalone) %>% arrange(mean)
#visualizing
autoplot(tune_abalone)
collect_metrics(tune_abalone) %>% arrange(mean)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
#rmse for training data
augment(ab_final_fit, new_data = data_train) %>%
rmse(truth = age, estimate = .pred) %>%
accuracy(truth = age, estimate = .pred)
#accuracy for training
augment(ab_final_fit, new_data = data_train) %>%
accuracy(truth = age, estimate = .pred)
#accuracy for training
augment(ab_final_fit, new_data = data_train) %>%
rsq(truth = age, estimate = .pred)
#rsq for testing
augment(ab_final_fit, new_data = data_test) %>%
rsq(truth = age, estimate = .pred)
#rsq for training
augment(ab_final_fit, new_data = data_train) %>%
rsq(truth = age, estimate = .pred)
#rmse for testing data
augment(ab_final_fit, new_data = data_test) %>%
rmse(truth = age, estimate = .pred)
#rsq for testing
augment(ab_final_fit, new_data = data_test) %>%
rsq(truth = age, estimate = .pred)
model_types = c("pruned tree","random forest","boosted tree")
tune_results = lst(tune_res, tune_param, tune_boost)
best_model = lst(best_penalty, best_params, best_boost)
final_models = lst(class_tree_final_fit, rf_tree_final_fit, boost_final_fit)
rocauc = c()
for (idx in 1:length(tune_results)){
performance_tbl <- collect_metrics(tune_results[[idx]]) %>% arrange(mean)
best_rocauc <- (filter(performance_tbl, .config == best_model[[idx]]['1', '.config'][[1]]))$mean
rocauc <- c(rocauc,best_rocauc)
}
# put the model types and their ROC AUC's into one table
combined <- as_tibble(cbind(model_types,rocauc))
combined
# using the table of rocaucs, find the model type with the best roc auc,
# and set "best_model" equal to that model's final workflow
best_model <- final_models[which.max(combined$rocauc)]
best_model
#re-fit on test data
test_mod <- augment(best_model[[1]], new_data = df_test)
test_mod
#ROC_AUC
test_mod %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
#ROC curves
test_mod %>%
roc_curve(truth = type_1, estimate = .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
