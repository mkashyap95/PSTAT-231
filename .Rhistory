boot_mean_func <- function(orig_vector, resample_vector) {
mean(orig_vector[resample_vector])
}
# R is number of replications
mean_results <- boot(x, boot_mean_func, R = 1000)
library(boot)
x <- c(rep(1, 337), rep(0, 421))
resamples <- lapply(1:1000, function(i) sample(x, replace = T))
boot.mean <- sapply(resamples, mean)
boot.mean
hist(boot.mean)
abline(v=mean(quantile(boot.mean, probs = 0.005),col="red",lwd=12))
abline(v=mean(quantile(boot.mean, probs = 0.995),col="red",lwd=12))
# 99% Confidence Interval:
c(quantile(boot.mean, probs = 0.005), quantile(boot.mean, probs = 0.995))
### Another way to get the 99% confidence interval using boot package ###
boot_mean_func <- function(orig_vector, resample_vector) {
mean(orig_vector[resample_vector])
}
# R is number of replications
mean_results <- boot(x, boot_mean_func, R = 1000)
tidy(mean_results)
boot.ci(mean_results, conf=0.99)
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_train)
?step_dummy
pokemon_recipe <- simple_rec1 %>%
step_dummy(legendary) %>%
step_dummy(generation) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
pokemon_recipe
?multinom_reg
reg1 <- multinom_reg(0 < mixture < 1, penalty = 0) %>%
reg1 <- multinom_reg(mixture = 0.5, penalty = 0) %>%
set_engine("glmnet")
reg1 <- multinom_reg(mixture = 0.5, penalty = tune()) %>%
set_engine("glmnet")
#workflow
elastic_workflow <- workflow() %>%
add_recipe(pokemon_recipe) %>%
add_model(reg1)
#tuning penalty
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)
penalty_grid
#tuning penalty
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 10)
penalty_grid
?grid_regular
mixture_grid <- grid_random(mixture(range = c(0,1)), levels = 10)
mixture_grid <- grid_random(mixture(range = c(0,1)), size = 10)
mixture_grid
#model
reg1 <- multinom_reg(mixture = tune(), penalty = tune()) %>%
set_engine("glmnet")
#workflow
elastic_workflow <- workflow() %>%
add_recipe(pokemon_recipe) %>%
add_model(reg1)
#tuning penalty
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 10)
penalty_grid
mixture_grid <- grid_random(mixture(range = c(0,1)), size = 10)
mixture_grid
?grid
?tune_grid
#combining grids to one dataframe
grid_df <- penalty_grid + mixture_grid
View(grid_df)
?as.data.frame
#combining grids to one dataframe
grid_df <- c(penalty_grid,mixture_grid)
#combining grids to one dataframe
grid_df <- as.data.fram(c(penalty_grid,mixture_grid))
#combining grids to one dataframe
grid_df <- as.data.frame(c(penalty_grid,mixture_grid))
#fitting model
tuned_mod <- tune_grid(elastic_workflow,
resamples = df_fold,
grid = grid_df)
install.packages("glmnet")
install.packages("glmnet")
install.packages("glmnet")
#fitting model
tuned_mod <- tune_grid(elastic_workflow,
resamples = df_fold,
grid = grid_df)
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_fold)
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_train)
#barplot
ggplot(df_clean, aes(x = type_1)) +
geom_bar(stat = "count", fill = "steelblue") +
theme_classic() +
coord_flip() +
xlab("Primary Type") +
ylab("Count")
#number of classes =18
summary(factor(df_clean$type_1))
#filtering data
df_filtered <- filter(df_clean, type_1 == "Bug" | type_1 == "Fire" | type_1 == "Grass" |
type_1 == "Normal" | type_1 == "Water" | type_1 == "Psychic")
#checking new dataframe
summary(factor(df_filtered$type_1))
#converting to factors
df_filtered$type_1 <- as.factor(df_filtered$type_1)
df_filtered$legendary <- as.factor(df_filtered$legendary)
set.seed(1212)
df_split <- initial_split(df_filtered, strata = "type_1")
df_train <- training(df_split)
df_test <- testing(df_split)
df_fold <- vfold_cv(df_train, v = 5, strata = "type_1")
View(df_train)
View(df_fold)
df_fold
set.seed(1212)
df_split <- initial_split(df_filtered, strata = "type_1")
df_train <- training(df_split)
df_test <- testing(df_split)
df_fold <- vfold_cv(df_train, v = 5, strata = "type_1")
pokemon_recipe
#model
reg1 <- multinom_reg(mixture = tune(), penalty = tune()) %>%
set_engine("glmnet")
#workflow
elastic_workflow <- workflow() %>%
add_recipe(pokemon_recipe) %>%
add_model(reg1)
#tuning penalty
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 10)
penalty_grid
mixture_grid <- grid_random(mixture(range = c(0,1)), size = 10)
mixture_grid
#combining grids to one dataframe
grid_df <- as.data.frame(c(penalty_grid,mixture_grid))
#fitting model
tuned_mod <- tune_grid(elastic_workflow,
resamples = df_fold,
grid = grid_df)
tuned_mod
autoplot(tuned_mod)
show_notes(.Last.tune.result)
View(df_train)
df_filtered$generation <- as.factor(df_filtered$generation)
set.seed(1212)
df_split <- initial_split(df_filtered, strata = "type_1")
df_train <- training(df_split)
df_test <- testing(df_split)
df_fold <- vfold_cv(df_train, v = 5, strata = "type_1")
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_train)
pokemon_recipe <- simple_rec1 %>%
step_dummy(legendary) %>%
step_dummy(generation) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
pokemon_recipe
#model
reg1 <- multinom_reg(mixture = tune(), penalty = tune()) %>%
set_engine("glmnet")
#workflow
elastic_workflow <- workflow() %>%
add_recipe(pokemon_recipe) %>%
add_model(reg1)
#tuning penalty
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 10)
penalty_grid
mixture_grid <- grid_random(mixture(range = c(0,1)), size = 10)
mixture_grid
#combining grids to one dataframe
grid_df <- as.data.frame(c(penalty_grid,mixture_grid))
#fitting model
tuned_mod <- tune_grid(elastic_workflow,
resamples = df_fold,
grid = grid_df)
tuned_mod
autoplot(tuned_mod)
?autoplot
collect_metrics(tuned_mod)
#best model
best_fit <- select_best(tuned_mod, metric = "rsq")
?select_best
#best model
best_fit <- select_best(tuned_mod)
autoplot(tuned_mod)
collect_metrics(tuned_mod)
?autoplot
collect_metrics(tuned_mod, metric = "accuracy")
collect_metrics(tuned_mod)
#best model
best_fit <- select_best(tuned_mod, metric = "accuracy")
best_fit
#best model
best_fit <- select_best(tuned_mod, metric = "roc_a")
#best model
best_fit <- select_best(tuned_mod, metric = "roc_auc")
best_fit
#finalizing workflow
final_mod <- finalize_workflow(elastic_workflow, best_fit)
#final fit
final_fit <- fit(final_mod, data = df_train)
#applying to testing data
augment(final_fit, new_data = df_test)
#applying to testing data
augment(final_fit, new_data = df_test) %>%
rsq(truth = Salary, estimate = .pred)
#applying to testing data
augment(final_fit, new_data = df_test) %>%
rsq(truth = type_1, estimate = .pred)
#applying to testing data
augment(final_fit, new_data = df_test)
#applying to testing data
augment(final_fit, new_data = df_test) %>%
rsq(truth = type_1, estimate = .pred_class)
?rsq
#applying to testing data
test_mod <- augment(final_fit, new_data = df_test)
View(test_mod)
#applying to testing data
augment(final_fit, new_data = df_test) %>%
rsq(truth = type_1, estimate = .pred_class)
?augment
#applying to testing data
augment(final_fit, new_data = df_test) %>%
multi_metric(truth = type_1, estimate = .pred_class) ##google this with wifi
?multi_metric
??multi_metric
#applying to testing data
augment(final_fit, new_data = df_test) %>%
conf_mat(truth = type_1, estimate = .pred_class) ##google this with wifi
#applying to testing data
augment(final_fit, new_data = df_test) %>%
roc_auc(truth = type_1, estimate = .pred_class) ##google this with wifi
#applying to testing data
augment(final_fit, new_data = df_test) %>%
accuracy(truth = type_1, estimate = .pred_class) ##google this with wifi
#applying to testing data
test_mod <- augment(final_fit, new_data = df_test) %>%
accuracy(truth = type_1, estimate = .pred_class) ##google this with wifi
View(test_mod)
#applying to testing data
test_mod <- augment(final_fit, new_data = df_test)
accuracy(test_mod,truth = type_1, estimate = .pred_class) ##google this with wifi
conf_mat(test_mod, truth = type_1, estimate = .pred_class)
View(df_test)
#roc curve for training data
roc_curve(final_fit, type_1, .pred_class)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_curve(final_fit, type_1, .pred_class)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_curve(type_1, .pred_class)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_auc(type_1, .pred_class)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_auc(type_1, .pred_Bug:.pred_Water)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_auc(type_1, .pred_Bug:.pred_Water)
#roc for testing data
roc_auc(test_mod, type_1, .pred_Bug:.pred_Water)
#roc for testing data
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_curve(type_1, .pred_Bug:.pred_Water)
#roc curves for each type
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water) %>%
autoplot()
#roc for testing data
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water) %>%
autoplot()
#roc for testing data
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water)
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_auc(type_1, .pred_Bug:.pred_Water)
#roc curves for each type
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water) %>%
autoplot()
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
#roc curve for training data
augment(final_fit, new_data = df_train) %>%
roc_auc(type_1, .pred_Bug:.pred_Water)
#roc for testing data
roc_auc(test_mod, type_1, .pred_Bug:.pred_Water)
#roc curves for each type
roc_curve(test_mod, type_1, .pred_Bug:.pred_Water) %>%
autoplot()
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
roc_auc(test_mod,truth = type_1, estimate = .pred_class)
roc_auc(test_mod,truth = type_1, estimate = .pred_Bug:.pred_Water)
accuracy(test_mod, truth = type_1, estimate = .pred_Bug:.pred_Water)
accuracy(test_mod, truth = type_1, estimate = .pred_class)
#heatmap
test_mod %>%
conf_mat(truth = type_1, estimate = .pred_class) %>%
autoplot(type = "heatmap")
?autoplot
autoplot(tuned_mod)
autoplot(tuned_mod, plotTable = TRUE)
autoplot(tuned_mod, ... = "Proportion of Lasso Penalty")
autoplot(tuned_mod, type = "marginals")
autoplot(tuned_mod, type = "performance")
autoplot(tuned_mod, type = "parameters")
autoplot(tuned_mod, type = "marginals")
autoplot(tuned_mod, ... = format())
autoplot(tuned_mod, format())
autoplot(tuned_mod, format(penalty))
autoplot(tuned_mod, format("penalty"))
autoplot(tuned_mod, format(penalty_grid))
pokemon <- read.csv("Pokemon.csv")
library(tidymodels)
library(tidyverse)
library(ggplot2)
pokemon <- read.csv("Pokemon.csv")
library(janitor)
pokemon_clean <- as.tibble(pokemon) %>%
clean_names()
pokemon_clean <- as_tibble(pokemon) %>%
clean_names()
View(pokemon_clean)
#visualizing
ggplot(pokemon_clean, aes(x = type_1)) +
geom_bar(stat = "count", fill = "steelblue") +
theme_classic() +
coord_flip() +
xlab("Primary Type") +
ylab("Count")
#filtering data
df_filtered <- filter(pokemon_clean, type_1 == "Bug" | type_1 == "Fire" | type_1 == "Grass"
| type_1 == "Normal" | type_1 == "Water" | type_1 == "Psychic")
#checking new dataframe
summary(factor(df_filtered$type_1))
#visualizing types
ggplot(pokemon_clean, aes(x = type_1)) +
geom_bar(stat = "count", fill = "steelblue") +
theme_classic() +
coord_flip() +
xlab("Primary Type") +
ylab("Count")
#converting to factors
df_filtered$type_1 <- as.factor(df_filtered$type_1)
df_filtered$legendary <- as.factor(df_filtered$legendary)
df_filtered$generation <- as.factor(df_filtered$generation)
#splitting data
set.seed(1212)
df_split <- initial_split(df_filtered, strata = "type_1")
df_train <- training(df_split)
df_test <- testing(df_split)
#v-fold
df_fold <- vfold_cv(df_train, v = 5, strata = "type_1")
#recipe
simple_rec1 <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense +
hp + sp_def, data = df_train)
pokemon_recipe <- simple_rec1 %>%
step_dummy(legendary) %>%
step_dummy(generation) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
pokemon_recipe
library(corrplot)
mat <- cor(df_train)
View(df_train)
summary(df_train)
?select
mat <- cor(select(df_train,type_1:legendary))
mat <- select(df_train,type_1:legendary)
View(mat)
?cor
mat <- select(df_train,total:speed)
corrplot(type = "lower", diag = F, method = 'color)
df_train %>%
select(is.numeric) %>%
cor() %>%
corrplot(type = "lower", diag = F, method = 'color')
df_train %>%
select(where(is.numeric)) %>%
cor() %>%
corrplot(type = "lower", diag = F, method = 'color')
mat <- select(is.numeric(df_train))
mat <- is.numeric(df_train)
mat <- select(df_train,total:generation)
mat %>%
cor() %>%
corrplot(type = "lower", diag = F, method = 'color')
mat <- select(df_train,total:speed)
mat %>%
cor() %>%
corrplot(type = "lower", diag = F, method = 'color')
tree_spec <- decision_tree() %>%
set_engine("rpart")
tree_spec <- decision_tree() %>%
set_engine("rpart") %>%
set_mode("classification")
#workflow
tree_wf <- workflow() %>%
add_recipe(pokemon_recipe) %>%
add_model(tree_spec)
#workflow
tree_wf <- workflow() %>%
add_recipe(pokemon_recipe %>% set_args(cost_complexity = tune())) %>%
add_model(tree_spec)
#workflow
tree_wf <- workflow() %>%
add_recipe(pokemon_recipe %>% set_args(cost_complexity = tune())) %>%
add_formula(pokemon_recipe)
?add_formula
#workflow
tree_wf <- workflow() %>%
add_recipe(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(pokemon_recipe)
#workflow
tree_wf <- workflow() %>%
add_recipe(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(pokemon_recipe)
#workflow
tree_wf <- workflow() %>%
add_recipe(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(pokemon_recipe, type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def, data = df_train)
#workflow
tree_wf <- workflow() %>%
add_model(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(pokemon_recipe, type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
#workflow
tree_wf <- workflow() %>%
add_model(tree_spec %>% set_args(cost_complexity = tune())) %>%
add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed +
defense + hp + sp_def)
set.seed(1212)
param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)
tune_res <- tune_grid(
tree_wf,
resamples = df_fold,
grid = param_grid,
metrics = metric_set(roc_auc)
)
View(tune_res)
#visualizing
autoplot(tune_res)
collect_metrics(tune_res)
?arrange
arrang(collect_metrics(tune_res))
arrange(collect_metrics(tune_res))
collect_metrics(tune_res)
best_penalty <- select_best(tune_res)
View(best_penalty)
best_penalty <- select_best(tune_res, metric = "rsq")
collect_metrics(tune_res)
best_penalty <- select_best(tune_res, metric = "roc_auc")
best_penalty
tune_res
tune_res %>%
collect_metrics() %>%
arrange(roc_auc)
#visualizing
autoplot(tune_res)
tune_res %>%
collect_metrics() %>%
arrange()
best_penalty
class_tree_final <- finalize_workflow(tree_wf, best_penalty)
class_tree_final_fit <- fit(class_tree_final, data = df_train)
#visualizing the tree
class_tree_final_fit %>%
extract_fit_engine() %>%
rpart.plot()
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
#visualizing the tree
class_tree_final_fit %>%
extract_fit_engine() %>%
rpart.plot()
#visualizing the tree
class_tree_final_fit %>%
extract_fit_engine() %>%
rpart.plot(model = T)
#visualizing the tree
class_tree_final_fit %>%
extract_fit_engine() %>%
rpart.plot()
library(randomForest)
install.packages("randomForest")
library(randomForest)
?rand_forest
rf_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
View(df_train)
p_grid <- grid_regular(mtry(range = c(1,8)),trees(range = c(100,500)), levels = 8)
p_grid <- grid_regular(mtry(range = c(1,8)),trees(range = c(100,500)),
min_n(range = c(1,10)), levels = 8)
View(p_grid)
