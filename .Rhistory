add_recipe(abalone_recipe)
summary(lm_wflow)
View(df)
question6 <- c("sex")
View(df)
question6 <- c("F",0.50,0.10,0.30,4,1,2,1)
question6 <- c("sex"="F",0.50,0.10,0.30,4,1,2,1)
as.data.frame?
as.data.frame()?
as.data.frame?
question6 <- as.data.fram(c("sex"="F",0.50,0.10,0.30,4,1,2,1))
question6 <- as.data.frame(c("sex"="F",0.50,0.10,0.30,4,1,2,1))
View(question6)
question6 <- as.data.frame(F",0.50,0.10,0.30,4,1,2,1))
question6 <- as.data.frame("F",0.50,0.10,0.30,4,1,2,1)
question6 <- as.data.frame(row.names = c('sex', 'length', 'diameter', 'ht', 'whole_wt',
'shucked_wt','viscera_wt', 'shell_wt'))
q6_prediction <- predict(lm_fit,c("F",0.50,0.10,0.30,4,1,2,1),contrasts=F)
#fitting to model and recipe
lm_fit <- fit(lm_wflow, abalone_train)
lm_fit %>%
extract_fit_parsnip() %>%
tidy()
q6_prediction <- predict(lm_fit,c("F",0.50,0.10,0.30,4,1,2,1),contrasts=F)
library(readxl)
question6 <- read_excel("question6.xlsx")
#"F",0.50,0.10,0.30,4,1,2,1)
q6_prediction <- predict(lm_fit,question6,contrasts=F)
View(question6)
#"F",0.50,0.10,0.30,4,1,2,1)
q6_prediction <- predict(lm_fit,new_data=question6)
q6_prediction
#metrics
abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics(abalone_train_res, truth = age, estimate = .pred)
#training RMSE
abalone_train_res <- predict(lm_fit, new_data = abalone_train %>% select(-age))
abalone_train_res %>%
head()
#reattaching column of actual observed age
abalone_train_res <- bind_cols(abalone_train_res, abalone_train %>% select(age))
abalone_train_res %>%
head()
#metrics
abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics(abalone_train_res, truth = age, estimate = .pred)
#training RMSE
abalone_train_res <- predict(lm_fit, new_data = abalone_train %>% select(-age))
abalone_train_res %>%
head()
#reattaching column of actual observed age
abalone_train_res <- bind_cols(abalone_train_res, abalone_train %>% select(age))
abalone_train_res %>%
head()
#metrics
abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics(abalone_train_res, truth = age, estimate = .pred)
#plotting predicted vs. observed
abalone_train_res %>%
ggplot(aes(x=.pred, y=jitter(age))) +
geom_point(alpha = 0.2) +
geom_abline(lty=2) +
theme_classic() +
coord_obs_pred()
#library(usethis)
#gitcreds::gitcreds_set()
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
#data
df <- read.csv("train.csv")
#converting to fcators
df$Survived <- as.factor(df$Survived)
df$Pclass <- as.factor(df$Pclass)
#changing reference group
new_df <- within(df, Survived <- relevel(Survived, ref = 1))
is.factor(df$Survived)
levels(df$Survived)
df$Survived_dummy <- levels = c("No","Yes")
df$Survived_dummy <- factor(df$Survived, levels = c("No","Yes"))
df$Survived <- factor(df$Survived, levels = c("No","Yes"))
#data
df <- read.csv("train.csv")
#converting to fcators
df$Survived <- as.factor(df$Survived)
df$Sex <- as.factor(df$Sex)
#changing reference group
new_df <- within(df, Survived <- relevel(Survived, ref = 1))
#checking frequencies
table(df$Survived)
table(df$Pclass)
table(df$Sex)
#splitting data
df_split <- initial_split(df, prop = 0.7, strata = Survived)
df_train <- training(df_split)
df_test <- testing(df_split)
# check frequency in training set
table(df_train$survived)
# check frequency in training set
table(df_train$Survived)
##
## Yes No
## 239 384
# make a bar plot
df_train %>%
ggplot(aes(x = Survived)) +
geom_bar()
?xlab
scale_x_discrete()
scale_x_discrete?
?scale_x_discrete
##
## Yes No
## 239 384
# make a bar plot
df_train %>%
ggplot(aes(x = Survived)) +
geom_bar() +
scale_x_discrete(labels = c("No","Yes"))
# visualize correlation matrix
cor_train <- df_train %>%
select(Age, SibSp, Parch, Fare) %>%
correlate()
?correlate
??correlate
library(discrim) # for discriminant analysis models
install.packages("discrim")
library(discrim) # for discriminant analysis models
library(discrim) # for discriminant analysis models
library(poissonreg) # for poisson regression
install.packages("poissonreg")
library(poissonreg) # for poisson regression
library(corrr) # for visualizing correlation matrices
install.packages("corrr")
library(corrr) # for visualizing correlation matrices
library(klaR) # for naive bayes
install.packages("klaR")
library(klaR) # for naive bayes
library(ggplot2) # for plots
library(ggthemes)
library(yardstick)
tidymodels_prefer()
# visualize correlation matrix
cor_train <- df_train %>%
select(Age, SibSp, Parch, Fare) %>%
correlate()
## Correlation computed with
## • Method: 'pearson'
## • Missing treated using: 'pairwise.complete.obs'
rplot(cor_train)
# create heatmap style correlation plot
cor_train %>%
stretch() %>%
ggplot(aes(x, y, fill = r)) +
geom_tile() +
geom_text(aes(label = as.character(fashion(r))))
# start the recipe
titanic_recipe <- recipe(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare,
data = df_train)
# get the information of the recipe
titanic_rec_info <- summary(titanic_recipe)
titanic_rec_info
df$Pclass <- as.factor(df$Pclass)
# start the recipe
titanic_recipe <- recipe(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare,
data = df_train)
# get the information of the recipe
titanic_rec_info <- summary(titanic_recipe)
titanic_rec_info
is.factor(df$Pclass)
is.factor(df_train$Pclass)
#library(usethis)
#gitcreds::gitcreds_set()
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
library(discrim) # for discriminant analysis models
library(poissonreg) # for poisson regression
library(corrr) # for visualizing correlation matrices
library(klaR) # for naive bayes
library(ggplot2) # for plots
library(ggthemes)
library(yardstick)
tidymodels_prefer()
#data
df <- read.csv("train.csv")
#converting to fcators
df$Survived <- as.factor(df$Survived)
df$Pclass <- as.factor(df$Pclass)
df$Sex <- as.factor(df$Sex)
#changing reference group
new_df <- within(df, Survived <- relevel(Survived, ref = 1))
#checking frequencies
table(df$Survived)
table(df$Pclass)
table(df$Sex)
#splitting data
df_split <- initial_split(df, prop = 0.7, strata = Survived)
df_train <- training(df_split)
df_test <- testing(df_split)
is.factor(df_train$Pclass)
# check frequency in training set
table(df_train$Survived)
##
## Yes No
## 239 384
# make a bar plot
df_train %>%
ggplot(aes(x = Survived)) +
geom_bar() +
scale_x_discrete(labels = c("No","Yes"))
# visualize correlation matrix
cor_train <- df_train %>%
select(Age, SibSp, Parch, Fare) %>%
correlate()
## Correlation computed with
## • Method: 'pearson'
## • Missing treated using: 'pairwise.complete.obs'
rplot(cor_train)
# create heatmap style correlation plot
cor_train %>%
stretch() %>%
ggplot(aes(x, y, fill = r)) +
geom_tile() +
geom_text(aes(label = as.character(fashion(r))))
# start the recipe
titanic_recipe <- recipe(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare,
data = df_train)
# get the information of the recipe
titanic_rec_info <- summary(titanic_recipe)
titanic_rec_info
# add steps
titanic_rec <- titanic_recipe %>%
step_impute_linear(age) %>% # deal with missing values from age
step_dummy(pclass) %>% # dummy code categorical predictors
step_dummy(sex) %>%
step_interact(terms = ~ starts_with("sex"):fare) %>% # create interaction t
erms
# add steps
titanic_rec <- titanic_recipe %>%
step_impute_linear(Age) %>% # deal with missing values from age
step_dummy(Pclass) %>% # dummy code categorical predictors
step_dummy(Sex) %>%
step_interact(terms = ~ starts_with("Sex"):Fare) %>% # create interaction terms
step_interact(terms = ~ Age:Fare)
# provide the summary of the recipe
titanic_rec
# specify logistic regression
log_reg <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
# create workflow
log_flow <- workflow() %>%
add_model(log_reg) %>%
add_recipe(titanic_rec)
# apply workflow to training data
log_fit <- fit(log_flow, df_train)
# view the results
log_fit %>% tidy()
# specify LDA
lda_mod <- discrim_linear() %>%
set_mode("classification") %>%
set_engine("MASS")
# create workflow
lda_flow <- workflow() %>%
add_model(lda_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
lda_fit <- fit(lda_flow, df_train)
# specify QDA
qda_mod <- discrim_quad() %>%
set_mode("classification") %>%
set_engine("MASS")
# create workflow
qda_flow <- workflow() %>%
add_model(qda_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
qda_fit <- fit(qda_flow, df_train)
# specify naive bayes
nb_mod <- naive_Bayes() %>%
set_mode("classification") %>%
set_engine("klaR") %>%
set_args(usekernel = FALSE) # assume predictors are drawn from Gaussian distribution
# create workflow
nb_flow <- workflow() %>%
add_model(nb_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
nb_fit <- fit(nb_flow, df_train)
# use the model to predict probabilities for the training data
log_reg_pred <- predict(log_fit, new_data = df_train, type = "prob")
log_reg_pred
# generate the confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = survived, estimate = .pred_class)
# generate the confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# create a visual representation of confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# calculate the accuracy
log_reg_acc <- augment(log_fit, new_data = df_train) %>%
accuracy(truth = Survived, estimate = .pred_class)
log_reg_acc
# use the model to predict probabilities for the training data
lda_pred <- predict(lda_fit, new_data = df_train, type = "prob")
lda_pred
# generate the confusion matrix
augment(lda_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
set.seed(1104)
#splitting data
df_split <- initial_split(df, prop = 0.7, strata = Survived)
df_train <- training(df_split)
df_test <- testing(df_split)
# check frequency in training set
table(df_train$Survived)
##
## Yes No
## 239 384
# make a bar plot
df_train %>%
ggplot(aes(x = Survived)) +
geom_bar() +
scale_x_discrete(labels = c("No","Yes"))
# visualize correlation matrix
cor_train <- df_train %>%
select(Age, SibSp, Parch, Fare) %>%
correlate()
## Correlation computed with
## • Method: 'pearson'
## • Missing treated using: 'pairwise.complete.obs'
rplot(cor_train)
# create heatmap style correlation plot
cor_train %>%
stretch() %>%
ggplot(aes(x, y, fill = r)) +
geom_tile() +
geom_text(aes(label = as.character(fashion(r))))
# start the recipe
titanic_recipe <- recipe(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare,
data = df_train)
# get the information of the recipe
titanic_rec_info <- summary(titanic_recipe)
titanic_rec_info
# add steps
titanic_rec <- titanic_recipe %>%
step_impute_linear(Age) %>% # deal with missing values from age
step_dummy(Pclass) %>% # dummy code categorical predictors
step_dummy(Sex) %>%
step_interact(terms = ~ starts_with("Sex"):Fare) %>% # create interaction terms
step_interact(terms = ~ Age:Fare)
# provide the summary of the recipe
titanic_rec
# specify logistic regression
log_reg <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
# create workflow
log_flow <- workflow() %>%
add_model(log_reg) %>%
add_recipe(titanic_rec)
# apply workflow to training data
log_fit <- fit(log_flow, df_train)
# view the results
log_fit %>% tidy()
# specify LDA
lda_mod <- discrim_linear() %>%
set_mode("classification") %>%
set_engine("MASS")
# create workflow
lda_flow <- workflow() %>%
add_model(lda_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
lda_fit <- fit(lda_flow, df_train)
# specify QDA
qda_mod <- discrim_quad() %>%
set_mode("classification") %>%
set_engine("MASS")
# create workflow
qda_flow <- workflow() %>%
add_model(qda_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
qda_fit <- fit(qda_flow, df_train)
# specify naive bayes
nb_mod <- naive_Bayes() %>%
set_mode("classification") %>%
set_engine("klaR") %>%
set_args(usekernel = FALSE) # assume predictors are drawn from Gaussian distribution
# create workflow
nb_flow <- workflow() %>%
add_model(nb_mod) %>%
add_recipe(titanic_rec)
# apply workflow to training data
nb_fit <- fit(nb_flow, df_train)
# use the model to predict probabilities for the training data
log_reg_pred <- predict(log_fit, new_data = df_train, type = "prob")
log_reg_pred
# generate the confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(log_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# calculate the accuracy
log_reg_acc <- augment(log_fit, new_data = df_train) %>%
accuracy(truth = Survived, estimate = .pred_class)
log_reg_acc
# use the model to predict probabilities for the training data
lda_pred <- predict(lda_fit, new_data = df_train, type = "prob")
lda_pred
# generate the confusion matrix
augment(lda_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(lda_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# calculate the accuracy
lda_acc <- augment(lda_fit, new_data = df_train) %>%
accuracy(truth = Survived, estimate = .pred_class)
lda_acc
# use the model to predict probabilities for the training data
qda_pred <- predict(qda_fit, new_data = df_train, type = "prob")
qda_pred
# generate the confusion matrix
augment(qda_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(qda_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# calculate the accuracy
qda_acc <- augment(qda_fit, new_data = df_train) %>%
accuracy(truth = Survived, estimate = .pred_class)
qda_acc
# use the model to predict probabilities for the training data
nb_pred <- predict(nb_fit, new_data = df_train, type = "prob")
nb_pred
# generate the confusion matrix
augment(nb_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(nb_fit, new_data = df_train) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# calculate the accuracy
nb_acc <- augment(nb_fit, new_data = df_train) %>%
accuracy(truth = Survived, estimate = .pred_class)
nb_acc
# provide a table of the predicted results for each of the four models
pred_table <- bind_cols(log_reg_pred, lda_pred, qda_pred, nb_pred)
pred_table
# compare model performance
accuracies <- c(log_reg_acc$.estimate, lda_acc$.estimate, qda_acc$.estimate, nb_acc$.estimate)
models <- c("Logistic Regression", "LDA", "QDA", "Naive Bayes")
results <- tibble(accuracies = accuracies, models = models)
results %>% arrange(-accuracies)
# generate the confusion matrix
augment(log_fit, new_data = df_test) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(log_fit, new_data = df_test) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# assess accuracy, sensitivity, and specificity
multi_metric <- metric_set(accuracy, sensitivity, specificity)
augment(log_fit, new_data = df_test) %>%
multi_metric(truth = Survived, estimate = .pred_class)
# create a ROC curve - Yes
augment(log_fit, new_data = df_test) %>%
roc_curve(Survived, .pred_Yes) %>%
autoplot()
# create a ROC curve - Yes
augment(log_fit, new_data = df_test) %>%
roc_curve(Survived, .pred_1) %>%
autoplot()
# create a ROC curve - No
augment(log_fit, new_data = df_test) %>%
roc_curve(Survived, .pred_0) %>%
autoplot()
# use the model to predict probabilities for the testing data
predict(log_fit, new_data = df_test, type = "prob")
# generate the confusion matrix
augment(log_fit, new_data = df_test) %>%
conf_mat(truth = Survived, estimate = .pred_class)
# create a visual representation of confusion matrix
augment(log_fit, new_data = df_test) %>%
conf_mat(truth = Survived, estimate = .pred_class) %>%
autoplot(type = "heatmap")
# assess accuracy, sensitivity, and specificity
multi_metric <- metric_set(accuracy, sensitivity, specificity)
augment(log_fit, new_data = df_test) %>%
multi_metric(truth = Survived, estimate = .pred_class)
# create a ROC curve - Yes
augment(log_fit, new_data = df_test) %>%
roc_curve(Survived, .pred_1) %>%
autoplot()
# create a ROC curve - No
augment(log_fit, new_data = df_test) %>%
roc_curve(Survived, .pred_0) %>%
autoplot()
